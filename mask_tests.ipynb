{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0c9a89",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d66884",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow numpy matplotlib pandas scikit-learn opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, Concatenate, Flatten, Dense, MaxPooling2D\n",
    "import keras.optimizers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transform_projection(image, rotation, shift, scale):\n",
    "    # # Separate alpha if present\n",
    "    # if image.shape[2] == 4:\n",
    "    #     alpha = image[:,:,3]\n",
    "    #     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGRA2RGBA)\n",
    "    # else:\n",
    "    #     alpha = None\n",
    "    #     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # ---- Parameters ----\n",
    "    shift_x, shift_y = shift     # pixels\n",
    "    rot_x, rot_y, rot_z = rotation   # degrees of 3D rotation\n",
    "\n",
    "    # ---- Build Projection Matrix ----\n",
    "    f = 500\n",
    "    cx, cy = w//2, h//2\n",
    "\n",
    "    \n",
    "\n",
    "    # Define corner points in 3D\n",
    "    corners_3d = np.array([\n",
    "        [-w/2, -h/2, 0],\n",
    "        [ w/2, -h/2, 0],\n",
    "        [ w/2,  h/2, 0],\n",
    "        [-w/2,  h/2, 0]\n",
    "    ])\n",
    "\n",
    "    # Apply rotation\n",
    "    R = rotation_matrix(rot_x, rot_y, rot_z)\n",
    "    rotated = corners_3d @ R.T\n",
    "\n",
    "    # Apply scaling\n",
    "    rotated *= scale\n",
    "\n",
    "    # Project back to 2D\n",
    "    projected = rotated.copy()\n",
    "    projected[:,0] = f * projected[:,0] / (f + projected[:,2]) + cx + shift_x\n",
    "    projected[:,1] = f * projected[:,1] / (f + projected[:,2]) + cy + shift_y\n",
    "\n",
    "    # Warp perspective\n",
    "    src_pts = np.array([[0,0],[w,0],[w,h],[0,h]], dtype=np.float32)\n",
    "    dst_pts = projected[:,:2].astype(np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "    output = cv2.warpPerspective(image, M, (w+200, h+200))\n",
    "    return output\n",
    "\n",
    "def rotation_matrix(rx, ry, rz):\n",
    "        rx, ry, rz = np.deg2rad([rx, ry, rz])\n",
    "        Rx = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(rx), -np.sin(rx)],\n",
    "                    [0, np.sin(rx),  np.cos(rx)]])\n",
    "        Ry = np.array([[ np.cos(ry), 0, np.sin(ry)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(ry), 0, np.cos(ry)]])\n",
    "        Rz = np.array([[np.cos(rz), -np.sin(rz), 0],\n",
    "                    [np.sin(rz),  np.cos(rz), 0],\n",
    "                    [0, 0, 1]])\n",
    "        return Rz @ Ry @ Rx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "focus = 'snow'  # Change to 'random', 'mud', or 'snow' as needed\n",
    "\n",
    "\n",
    "if focus == 'random':\n",
    "    texture = np.random.randint(0, 256, (16, 16, 3), dtype=np.uint8)\n",
    "elif focus == 'mud':\n",
    "    texture = np.array(Image.open('textures/mud.png').convert('RGB').resize((100, 100), resample=Image.NEAREST))\n",
    "elif focus == 'snow':\n",
    "    texture = np.array(Image.open('textures/snow.png').convert('RGB').resize((100, 100), resample=Image.NEAREST))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# COMMENT THIS OUT IF YOU WANT TO TILE THE TEXTURE REPEATEDLY OVER 500x500 AREA\n",
    "# texture = np.array(\n",
    "#     Image.fromarray(texture).resize((500, 500), resample=Image.NEAREST)\n",
    "# )\n",
    "\n",
    "plt.imshow(texture)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tile the texture repeatedly over the 500x500 image\n",
    "# tile_rows = 500 // texture.shape[0] + 1\n",
    "# tile_cols = 500 // texture.shape[1] + 1\n",
    "\n",
    "# tiled_texture = np.tile(texture, (tile_rows, tile_cols, 1))[:500, :500, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "canvas = np.zeros((500, 500, 3), dtype=texture.dtype)\n",
    "tex_h, tex_w = texture.shape[:2]\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "for y in range(0, 500, tex_h + np.random.randint(0, 30)):\n",
    "    for x in range(0, 500, tex_w + np.random.randint(0, 30)):\n",
    "        y_end = min(y + tex_h, 500)\n",
    "        x_end = min(x + tex_w, 500)\n",
    "        # Compute region to paste\n",
    "        region_h = y_end - y\n",
    "        region_w = x_end - x\n",
    "        canvas[y:y_end, x:x_end] = texture[:region_h, :region_w]\n",
    "\n",
    "tiled_texture = canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "\n",
    "rotation = (randint(0,10), randint(0,20), randint(0,45))\n",
    "\n",
    "transformed_tex = transform_projection(tiled_texture, rotation, (40, 40), scale = 2.2) # scale = 1.0 --> no scaling\n",
    "\n",
    "# ---- Display ----\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(tiled_texture)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Transformed (shift+scale+3D rot)\")\n",
    "plt.imshow(transformed_tex)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, image_size=(500, 500)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.png')) + glob(os.path.join(folder, '*.jpg')))\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = keras.preprocessing.image.load_img(path, target_size=image_size)\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "        img = img / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "print(\"Loading validation datasets...\")\n",
    "val_x_ref = load_images_from_folder('validation_dataset_clean/reference')\n",
    "val_eta_exp = load_images_from_folder('validation_dataset_clean/texture')\n",
    "val_x_ren = load_images_from_folder('validation_dataset_clean/rendered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.any(val_eta_exp[65] > 0.01, axis=-1, keepdims=True)  # Shape: (500, 500, 1)\n",
    "\n",
    "# Apply texture to masked regions\n",
    "texture_mask = np.where(mask, tiled_texture, 0.0)\n",
    "\n",
    "plt.imshow(texture_mask.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display(model, ref, tex, cross_ref):\n",
    "    outputs = model.predict([ref, tex])\n",
    "\n",
    "    # Compute intersection (where rendered and reference are nearly equal)\n",
    "    intersection_mask = np.isclose(cross_ref, ref, atol=1e-2)\n",
    "\n",
    "    # Overlay: only keep intersecting pixels in prediction\n",
    "    overlay_preds = np.where(intersection_mask, ref, outputs[0])\n",
    "\n",
    "    plt.imshow(overlay_preds[0])\n",
    "    plt.axis('off')\n",
    "    plt.title('Model Output')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = keras.models.load_model('models/k3_12epch_wo_custom_loss_model.h5', compile=False)\n",
    "\n",
    "input1 = np.expand_dims(val_x_ref[65], axis=0)  # shape: (1, 500, 500, 3)\n",
    "input2 = np.expand_dims(texture_mask, axis=0)  # shape: (1, 500, 500, 3)\n",
    "cross_ref = np.expand_dims(val_x_ren[65], axis=0)  # shape: (1, 500, 500, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_display(model, input1, input2, cross_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede39750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add object recognition model\n",
    "# compute losses of all saved models - DONE\n",
    "# real-word conditions textures (snow, dirt, etc.) - DONE\n",
    "# MAYBE RE-TRAIN MODELS WITH LESS NODES? COLOURISARION ISSUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710275a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mse_dict = {}\n",
    "\n",
    "for model_path in os.listdir('models'):\n",
    "    print(f\"Processing model: {model_path}\")\n",
    "    \n",
    "    if model_path == 'k3_50epch_custom_loss_w_fit().h5':\n",
    "        class CustomModel(tf.keras.Model):\n",
    "            def train_step(self, data):\n",
    "                (x_ref, eta_exp), y_true = data\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    outputs = self([x_ref, eta_exp], training=True)\n",
    "                    y_pred = outputs[\"prediction\"]\n",
    "                    x_ref_passthrough = outputs[\"x_ref_passthrough\"]\n",
    "\n",
    "                    # Calculate intersection mask\n",
    "                    epsilon = 1e-2\n",
    "                    mask = tf.cast(tf.abs(y_true - x_ref_passthrough) > epsilon, tf.float32)\n",
    "                    sq_diff = tf.square(y_true - y_pred)\n",
    "                    masked_sq_diff = sq_diff * mask\n",
    "                    loss = tf.reduce_sum(masked_sq_diff) / (tf.reduce_sum(mask) + 1e-8)\n",
    "\n",
    "                # Compute gradients\n",
    "                trainable_vars = self.trainable_variables\n",
    "                gradients = tape.gradient(loss, trainable_vars)\n",
    "                self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "                return {\"loss\": loss}\n",
    "        \n",
    "        model = keras.models.load_model(f'models/{model_path}', compile=False, custom_objects={'CustomModel': CustomModel})\n",
    "        # Predict\n",
    "        preds = model.predict([val_x_ref, val_eta_exp])['prediction']\n",
    "\n",
    "    else:\n",
    "        # Load the model\n",
    "        model = keras.models.load_model(f'models/{model_path}', compile=False)\n",
    "\n",
    "        # Predict\n",
    "        preds = model.predict([val_x_ref, val_eta_exp])\n",
    "\n",
    "    # Compute intersection (where rendered and reference are nearly equal)\n",
    "    intersection_mask = np.isclose(val_x_ren, val_x_ref, atol=1e-2)\n",
    "\n",
    "    # Overlay: only keep intersecting pixels in prediction\n",
    "    overlay_preds = np.where(intersection_mask, val_x_ref, preds)\n",
    "    # overlay_preds = np.where(intersection_mask, preds, 0.0)\n",
    "\n",
    "    avg_mse = sklearn.metrics.mean_squared_error(val_x_ren.ravel(), overlay_preds.ravel())\n",
    "\n",
    "\n",
    "    print(\"Average MSE: \", avg_mse)\n",
    "\n",
    "    mse_dict[model_path] = avg_mse\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE Dictionary: \", mse_dict)\n",
    "print(\"Models sorted by MSE:\")\n",
    "for model_path, mse in sorted(mse_dict.items(), key=lambda x: x[1]):\n",
    "    print(f\"{model_path}: {mse}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar([1,2,3,4,5,6,7], list(mse_dict.values()), color='skyblue')\n",
    "plt.xlabel('Structure serial number')\n",
    "plt.ylabel('Value')\n",
    "plt.title('MSE for 1-3 Structure')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
