{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0c9a89",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d66884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (1.21.6)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: opencv-python in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (4.13.0.90)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.62.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow)\n",
      "  Using cached h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting keras<2.12,>=2.11.0 (from tensorflow)\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (from tensorflow) (23.2)\n",
      "Collecting protobuf<3.20,>=3.9.2 (from tensorflow)\n",
      "  Using cached protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
      "Requirement already satisfied: setuptools in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.12,>=2.11 (from tensorflow)\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow)\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.34.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (14 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl.metadata (138 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Using cached Pillow-9.5.0-cp37-cp37m-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (from matplotlib) (2.9.0)\n",
      "Collecting pytz>=2017.3 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting scipy>=1.1.0 (from scikit-learn)\n",
      "  Using cached scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Downloading google_auth-2.45.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached Werkzeug-2.2.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached importlib_metadata-6.7.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lunet/cosr6/.conda/envs/carla37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2024.8.30)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached zipp-3.15.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Using cached tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "Using cached matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.62.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "Using cached h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Using cached kiwisolver-1.4.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached Pillow-9.5.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Using cached protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.34.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Using cached wrapt-1.16.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Downloading google_auth-2.45.0-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached charset_normalizer-3.4.4-py3-none-any.whl (53 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pytz, libclang, flatbuffers, zipp, wrapt, urllib3, typing-extensions, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, scipy, pyparsing, pyasn1, protobuf, pillow, opt-einsum, oauthlib, MarkupSafe, keras, joblib, idna, h5py, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, cachetools, astunparse, absl-py, werkzeug, scikit-learn, rsa, requests, pyasn1-modules, pandas, kiwisolver, importlib-metadata, requests-oauthlib, matplotlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.5.2 charset-normalizer-3.4.4 cycler-0.11.0 flatbuffers-25.12.19 fonttools-4.38.0 gast-0.4.0 google-auth-2.45.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.62.3 h5py-3.8.0 idna-3.10 importlib-metadata-6.7.0 joblib-1.3.2 keras-2.11.0 kiwisolver-1.4.5 libclang-18.1.1 markdown-3.4.4 matplotlib-3.5.3 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-1.3.5 pillow-9.5.0 protobuf-3.19.6 pyasn1-0.5.1 pyasn1-modules-0.3.0 pyparsing-3.1.4 pytz-2025.2 requests-2.31.0 requests-oauthlib-2.0.0 rsa-4.9.1 scikit-learn-1.0.2 scipy-1.7.3 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 threadpoolctl-3.1.0 typing-extensions-4.7.1 urllib3-2.0.7 werkzeug-2.2.3 wrapt-1.16.0 zipp-3.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 17:39:54.100585: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-25 17:39:55.088578: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-25 17:39:55.289262: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2026-01-25 17:39:55.289276: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2026-01-25 17:39:57.824697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2026-01-25 17:39:57.825081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2026-01-25 17:39:57.825087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow numpy matplotlib pandas scikit-learn opencv-python\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, Concatenate, Flatten, Dense, MaxPooling2D\n",
    "import keras.optimizers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cda555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transform_projection(image, rotation, shift, scale):\n",
    "    # # Separate alpha if present\n",
    "    # if image.shape[2] == 4:\n",
    "    #     alpha = image[:,:,3]\n",
    "    #     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGRA2RGBA)\n",
    "    # else:\n",
    "    #     alpha = None\n",
    "    #     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # ---- Parameters ----\n",
    "    shift_x, shift_y = shift     # pixels\n",
    "    rot_x, rot_y, rot_z = rotation   # degrees of 3D rotation\n",
    "\n",
    "    # ---- Build Projection Matrix ----\n",
    "    f = 500\n",
    "    cx, cy = w//2, h//2\n",
    "\n",
    "    \n",
    "\n",
    "    # Define corner points in 3D\n",
    "    corners_3d = np.array([\n",
    "        [-w/2, -h/2, 0],\n",
    "        [ w/2, -h/2, 0],\n",
    "        [ w/2,  h/2, 0],\n",
    "        [-w/2,  h/2, 0]\n",
    "    ])\n",
    "\n",
    "    # Apply rotation\n",
    "    R = rotation_matrix(rot_x, rot_y, rot_z)\n",
    "    rotated = corners_3d @ R.T\n",
    "\n",
    "    # Apply scaling\n",
    "    rotated *= scale\n",
    "\n",
    "    # Project back to 2D\n",
    "    projected = rotated.copy()\n",
    "    projected[:,0] = f * projected[:,0] / (f + projected[:,2]) + cx + shift_x\n",
    "    projected[:,1] = f * projected[:,1] / (f + projected[:,2]) + cy + shift_y\n",
    "\n",
    "    # Warp perspective\n",
    "    src_pts = np.array([[0,0],[w,0],[w,h],[0,h]], dtype=np.float32)\n",
    "    dst_pts = projected[:,:2].astype(np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "    output = cv2.warpPerspective(image, M, (w+200, h+200))\n",
    "    return output\n",
    "\n",
    "def rotation_matrix(rx, ry, rz):\n",
    "        rx, ry, rz = np.deg2rad([rx, ry, rz])\n",
    "        Rx = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(rx), -np.sin(rx)],\n",
    "                    [0, np.sin(rx),  np.cos(rx)]])\n",
    "        Ry = np.array([[ np.cos(ry), 0, np.sin(ry)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(ry), 0, np.cos(ry)]])\n",
    "        Rz = np.array([[np.cos(rz), -np.sin(rz), 0],\n",
    "                    [np.sin(rz),  np.cos(rz), 0],\n",
    "                    [0, 0, 1]])\n",
    "        return Rz @ Ry @ Rx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aea189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "focus = 'random'  # Change to 'random', 'mud', or 'snow' as needed\n",
    "\n",
    "\n",
    "if focus == 'random':\n",
    "    texture = np.random.randint(0, 256, (16, 16, 3), dtype=np.uint8)\n",
    "elif focus == 'mud':\n",
    "    texture = np.array(Image.open('textures/mud.png').convert('RGB').resize((100, 100), resample=Image.NEAREST))\n",
    "elif focus == 'snow':\n",
    "    texture = np.array(Image.open('textures/snow.png').convert('RGB').resize((100, 100), resample=Image.NEAREST))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# COMMENT THIS OUT IF YOU WANT TO TILE THE TEXTURE REPEATEDLY OVER 500x500 AREA\n",
    "# texture = np.array(\n",
    "#     Image.fromarray(texture).resize((500, 500), resample=Image.NEAREST)\n",
    "# )\n",
    "\n",
    "plt.imshow(texture)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tile the texture repeatedly over the 500x500 image\n",
    "# tile_rows = 500 // texture.shape[0] + 1\n",
    "# tile_cols = 500 // texture.shape[1] + 1\n",
    "\n",
    "# tiled_texture = np.tile(texture, (tile_rows, tile_cols, 1))[:500, :500, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "canvas = np.zeros((500, 500, 3), dtype=texture.dtype)\n",
    "tex_h, tex_w = texture.shape[:2]\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "for y in range(0, 500, tex_h + np.random.randint(0, 30)):\n",
    "    for x in range(0, 500, tex_w + np.random.randint(0, 30)):\n",
    "        y_end = min(y + tex_h, 500)\n",
    "        x_end = min(x + tex_w, 500)\n",
    "        # Compute region to paste\n",
    "        region_h = y_end - y\n",
    "        region_w = x_end - x\n",
    "        canvas[y:y_end, x:x_end] = texture[:region_h, :region_w]\n",
    "\n",
    "tiled_texture = canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66edae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "\n",
    "rotation = (randint(0,10), randint(0,20), randint(0,45))\n",
    "\n",
    "transformed_tex = transform_projection(tiled_texture, rotation, (40, 40), scale = 2.2) # scale = 1.0 --> no scaling\n",
    "\n",
    "# ---- Display ----\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(tiled_texture)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Transformed (shift+scale+3D rot)\")\n",
    "plt.imshow(transformed_tex)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, image_size=(500, 500)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.png')) + glob(os.path.join(folder, '*.jpg')))\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = keras.preprocessing.image.load_img(path, target_size=image_size)\n",
    "        img = keras.preprocessing.image.img_to_array(img)\n",
    "        img = img / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "print(\"Loading validation datasets...\")\n",
    "val_x_ref = load_images_from_folder('validation_dataset_clean/reference')\n",
    "val_eta_exp = load_images_from_folder('validation_dataset_clean/texture')\n",
    "val_x_ren = load_images_from_folder('validation_dataset_clean/rendered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.any(val_eta_exp[65] > 0.01, axis=-1, keepdims=True)  # Shape: (500, 500, 1)\n",
    "\n",
    "# Apply texture to masked regions\n",
    "texture_mask = np.where(mask, tiled_texture, 0.0)\n",
    "\n",
    "plt.imshow(texture_mask.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display(model, ref, tex, cross_ref):\n",
    "    outputs = model.predict([ref, tex])\n",
    "\n",
    "    # Compute intersection (where rendered and reference are nearly equal)\n",
    "    intersection_mask = np.isclose(cross_ref, ref, atol=1e-2)\n",
    "\n",
    "    # Overlay: only keep intersecting pixels in prediction\n",
    "    overlay_preds = np.where(intersection_mask, ref, outputs[0])\n",
    "\n",
    "    plt.imshow(overlay_preds[0])\n",
    "    plt.axis('off')\n",
    "    plt.title('Model Output')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = keras.models.load_model('models/k3_12epch_wo_custom_loss_model.h5', compile=False)\n",
    "\n",
    "input1 = np.expand_dims(val_x_ref[65], axis=0)  # shape: (1, 500, 500, 3)\n",
    "input2 = np.expand_dims(texture_mask, axis=0)  # shape: (1, 500, 500, 3)\n",
    "cross_ref = np.expand_dims(val_x_ren[65], axis=0)  # shape: (1, 500, 500, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_display(model, input1, input2, cross_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede39750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add object recognition model\n",
    "# compute losses of all saved models - DONE\n",
    "# real-word conditions textures (snow, dirt, etc.) - DONE\n",
    "# MAYBE RE-TRAIN MODELS WITH LESS NODES? COLOURISARION ISSUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710275a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mse_dict = {}\n",
    "\n",
    "for model_path in os.listdir('models'):\n",
    "    print(f\"Processing model: {model_path}\")\n",
    "    \n",
    "    if model_path == 'k3_50epch_custom_loss_w_fit().h5':\n",
    "        class CustomModel(tf.keras.Model):\n",
    "            def train_step(self, data):\n",
    "                (x_ref, eta_exp), y_true = data\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    outputs = self([x_ref, eta_exp], training=True)\n",
    "                    y_pred = outputs[\"prediction\"]\n",
    "                    x_ref_passthrough = outputs[\"x_ref_passthrough\"]\n",
    "\n",
    "                    # Calculate intersection mask\n",
    "                    epsilon = 1e-2\n",
    "                    mask = tf.cast(tf.abs(y_true - x_ref_passthrough) > epsilon, tf.float32)\n",
    "                    sq_diff = tf.square(y_true - y_pred)\n",
    "                    masked_sq_diff = sq_diff * mask\n",
    "                    loss = tf.reduce_sum(masked_sq_diff) / (tf.reduce_sum(mask) + 1e-8)\n",
    "\n",
    "                # Compute gradients\n",
    "                trainable_vars = self.trainable_variables\n",
    "                gradients = tape.gradient(loss, trainable_vars)\n",
    "                self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "                return {\"loss\": loss}\n",
    "        \n",
    "        model = keras.models.load_model(f'models/{model_path}', compile=False, custom_objects={'CustomModel': CustomModel})\n",
    "        # Predict\n",
    "        preds = model.predict([val_x_ref, val_eta_exp])['prediction']\n",
    "\n",
    "    else:\n",
    "        # Load the model\n",
    "        model = keras.models.load_model(f'models/{model_path}', compile=False)\n",
    "\n",
    "        # Predict\n",
    "        preds = model.predict([val_x_ref, val_eta_exp])\n",
    "\n",
    "    # Compute intersection (where rendered and reference are nearly equal)\n",
    "    intersection_mask = np.isclose(val_x_ren, val_x_ref, atol=1e-2)\n",
    "\n",
    "    # Overlay: only keep intersecting pixels in prediction\n",
    "    overlay_preds = np.where(intersection_mask, val_x_ref, preds)\n",
    "    # overlay_preds = np.where(intersection_mask, preds, 0.0)\n",
    "\n",
    "    avg_mse = sklearn.metrics.mean_squared_error(val_x_ren.ravel(), overlay_preds.ravel())\n",
    "\n",
    "\n",
    "    print(\"Average MSE: \", avg_mse)\n",
    "\n",
    "    mse_dict[model_path] = avg_mse\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE Dictionary: \", mse_dict)\n",
    "print(\"Models sorted by MSE:\")\n",
    "for model_path, mse in sorted(mse_dict.items(), key=lambda x: x[1]):\n",
    "    print(f\"{model_path}: {mse}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar([1,2,3,4,5,6,7], list(mse_dict.values()), color='skyblue')\n",
    "plt.xlabel('Structure serial number')\n",
    "plt.ylabel('Value')\n",
    "plt.title('MSE for 1-3 Structure')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
