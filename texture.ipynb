{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a1c5f5",
   "metadata": {},
   "source": [
    "ðŸŽ¨ DTA Texture Generation: PseudocodeThe goal is to find the pixel values for the small Base Texture ($\\mathbf{\\eta}_{adv\\_b}$) that minimizes the target object's detection confidence across all sampled views.1. Setup and InitializationCode snippet\n",
    "\n",
    "// 1. Initialize the only trainable variable\n",
    "Initialise Base_Texture (eta_adv_b) with random pixel values (e.g., 16x16x3).\n",
    "\n",
    "// 2. Set up the training infrastructure\n",
    "Set Optimizer (e.g., Adam) to update Base_Texture.\n",
    "Load Trained_DTN_Model (f_omega).\n",
    "Load Target_Detector_Model (h_theta).\n",
    "Define Transformation_Set (T) of all possible camera poses, lights, etc.\n",
    "\n",
    "// 3. Define the EOT Loss function\n",
    "FUNCTION Calculate_Attack_Loss(Detector_Output):\n",
    "    Find Maximum_Car_Confidence (C_max) from Detector_Output.\n",
    "    Return Average_Loss = -log(1 - C_max) across the batch.\n",
    "END FUNCTION\n",
    "2. The Optimization Loop (EOT)The optimization loop runs for hundreds of iterations (epochs) to refine the base texture.Code snippetFOR each optimization_step (epoch):\n",
    "    // -- Step A: Sampling and Data Retrieval (The EOT Input) --\n",
    "    // Sample a minibatch of scene conditions from T (Expectation Over Transformation)\n",
    "    Sample Minibatch_of_Transformations (T_batch) from Transformation_Set (T).\n",
    "    \n",
    "    // Retrieve the corresponding data from the rendering engine for this minibatch\n",
    "    Get Reference_Images (X_ref) \n",
    "    Get Segmentation_Masks (X_seg) \n",
    "    Get Original_Images (X_orig)\n",
    "    \n",
    "    // -- Step B: The Differentiable Forward Pass --\n",
    "    START Gradient_Tracking (Tape)\n",
    "\n",
    "        // 1. Repeated Texture Projection (Pattern Alignment)\n",
    "        // Calculate Projection_Matrices (M) based on each transformation in T_batch (phi + phi_rd).\n",
    "        // Apply M to Base_Texture (eta_adv_b) to create the large, projected pattern.\n",
    "        Projected_Texture (eta_adv_p) = Project(Base_Texture, M_shift, M_scale, M_3DRot)\n",
    "        \n",
    "        // 2. Masking\n",
    "        Masked_Texture (eta_adv) = Projected_Texture * Segmentation_Masks (X_seg)\n",
    "\n",
    "        // 3. DTN Rendering\n",
    "        // The DTN simulates photo-realistic rendering of the new texture.\n",
    "        Rendered_Object_Image (X_adv_rendered) = Trained_DTN_Model(Reference_Images, Masked_Texture)\n",
    "\n",
    "        // 4. Scene Reconstruction\n",
    "        // Combine the new rendered object with the original scene background.\n",
    "        Final_Adversarial_Image (X_adv) = X_adv_rendered + (X_orig - X_seg)\n",
    "\n",
    "        // 5. Detection and Loss Calculation\n",
    "        Detector_Output = Target_Detector_Model(Final_Adversarial_Image)\n",
    "        Attack_Loss (L_atk) = Calculate_Attack_Loss(Detector_Output)\n",
    "\n",
    "    // -- Step C: Backpropagation and Update --\n",
    "    \n",
    "    // Calculate the gradient of the loss with respect to the Base_Texture\n",
    "    Gradient = Tape.Get_Gradient(Attack_Loss, Base_Texture)\n",
    "\n",
    "    // Update the Base_Texture's pixel values to minimize the loss\n",
    "    Optimizer.Apply_Gradient(Gradient, Base_Texture)\n",
    "\n",
    "END FOR\n",
    "\n",
    "// Final_Texture is the Base_Texture (eta_adv_b) after all updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
