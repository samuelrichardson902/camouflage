{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6291a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (1.21.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (4.13.0.92)\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.62.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (25.12.19)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting jupyterlab_widgets~=3.0.15\n",
      "  Using cached jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (7.34.0)\n",
      "Collecting comm>=0.1.3\n",
      "  Using cached comm-0.1.4-py3-none-any.whl (6.6 kB)\n",
      "Collecting widgetsnbextension~=4.0.14\n",
      "  Using cached widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: pygments in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.45.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (6.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, comm, ipywidgets\n",
      "Successfully installed comm-0.1.4 ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, Concatenate, Flatten, Dense, MaxPooling2D\n",
    "import keras.optimizers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03978456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, image_size=(500, 500), numImgs = (0, 100)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.png')) + glob(os.path.join(folder, '*.jpg')))\n",
    "    paths = sorted(paths, key=lambda x:int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    paths = paths[numImgs[0]:numImgs[1]]\n",
    "\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = tf.keras.utils.load_img(path, target_size=image_size)\n",
    "        img = tf.keras.utils.img_to_array(img).astype(np.float32)\n",
    "        img = img / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "\n",
    "# [[distance, pitch, yaw, vehicle_id_string],...]\n",
    "def load_transforms(folder, numImgs = (0, 100)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.npy')))\n",
    "    paths = sorted(paths, key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    paths = paths[numImgs[0]:numImgs[1]]\n",
    "\n",
    "    transforms = []\n",
    "    for path in paths:\n",
    "        data = np.load(path) \n",
    "        transforms.append(data)\n",
    "    \n",
    "    return np.array(transforms)\n",
    "\n",
    "\n",
    "dataset_folder = 'sample_dataset'\n",
    "imgsToLoad = (101, 209)\n",
    "sample_references = load_images_from_folder(f\"{dataset_folder}/reference\", numImgs = imgsToLoad)\n",
    "sample_masks = load_images_from_folder(f\"{dataset_folder}/masks\", numImgs = imgsToLoad)\n",
    "sample_overlays = load_images_from_folder(f\"{dataset_folder}/overlays\", numImgs = imgsToLoad)\n",
    "sample_transforms = load_transforms(f\"{dataset_folder}/transforms\", numImgs = imgsToLoad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe48505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcTransforms(pitch, yaw):\n",
    "    yawdiff = ((yaw + 45) % 90) - 45 #the difference of yaw from the nearest 90 degree multiple\n",
    "    if pitch > 35: # top face is predominant\n",
    "        pitch = -pitch\n",
    "        yaw = -yawdiff\n",
    "        roll = 0\n",
    "\n",
    "    elif pitch < 15: # lowest orbit angle\n",
    "        pitch = pitch\n",
    "        roll = -yawdiff\n",
    "        yaw = 0\n",
    "    \n",
    "    else: # mid orbit angle\n",
    "        if 145 < yaw < 215: #if on front face\n",
    "            yaw = -yawdiff\n",
    "            pitch = -pitch\n",
    "            roll = 0\n",
    "\n",
    "        else:\n",
    "            roll = -yawdiff\n",
    "            yaw = 0\n",
    "\n",
    "    return pitch, yaw, roll\n",
    "\n",
    "\n",
    "def get_rotation_matrix_tf(pitch, yaw, roll):\n",
    "    # Convert to radians\n",
    "    deg2rad = np.pi / 180.0\n",
    "    p = pitch * deg2rad\n",
    "    y = yaw * deg2rad\n",
    "    r = roll * deg2rad\n",
    "\n",
    "    rot_pitch = tf.stack([\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, tf.cos(p), -tf.sin(p)],\n",
    "        [0.0, tf.sin(p),  tf.cos(p)]\n",
    "    ])\n",
    "    \n",
    "    rot_roll = tf.stack([\n",
    "        [ tf.cos(r), 0.0, tf.sin(r)],\n",
    "        [ 0.0,       1.0, 0.0],\n",
    "        [-tf.sin(r), 0.0, tf.cos(r)]\n",
    "    ])\n",
    "    \n",
    "    rot_yaw = tf.stack([\n",
    "        [tf.cos(y), -tf.sin(y), 0.0],\n",
    "        [tf.sin(y),  tf.cos(y), 0.0],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    \n",
    "\n",
    "    #mult rotations together (yaw -> roll -> pitch)\n",
    "    rot = tf.matmul(rot_pitch, tf.matmul(rot_roll, rot_yaw))\n",
    "    \n",
    "    return rot\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b50a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_sampler_tf(img, x, y):\n",
    "    H = tf.shape(img)[0]\n",
    "    W = tf.shape(img)[1]\n",
    "    H_f = tf.cast(H, tf.float32)\n",
    "    W_f = tf.cast(W, tf.float32)\n",
    "    \n",
    "    x = tf.clip_by_value(x, 0.0, W_f - 1.001)\n",
    "    y = tf.clip_by_value(y, 0.0, H_f - 1.001)\n",
    "    \n",
    "    x0 = tf.cast(tf.floor(x), tf.int32)\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(tf.floor(y), tf.int32)\n",
    "    y1 = y0 + 1\n",
    "    \n",
    "    Ia = tf.gather_nd(img, tf.stack([y0, x0], axis=-1))\n",
    "    Ib = tf.gather_nd(img, tf.stack([y1, x0], axis=-1))\n",
    "    Ic = tf.gather_nd(img, tf.stack([y0, x1], axis=-1))\n",
    "    Id = tf.gather_nd(img, tf.stack([y1, x1], axis=-1))\n",
    "    \n",
    "    wa = (tf.cast(x1, tf.float32) - x) * (tf.cast(y1, tf.float32) - y)\n",
    "    wb = (tf.cast(x1, tf.float32) - x) * (y - tf.cast(y0, tf.float32))\n",
    "    wc = (x - tf.cast(x0, tf.float32)) * (tf.cast(y1, tf.float32) - y)\n",
    "    wd = (x - tf.cast(x0, tf.float32)) * (y - tf.cast(y0, tf.float32))\n",
    "    \n",
    "    wa = tf.expand_dims(wa, -1)\n",
    "    wb = tf.expand_dims(wb, -1)\n",
    "    wc = tf.expand_dims(wc, -1)\n",
    "    wd = tf.expand_dims(wd, -1)\n",
    "    \n",
    "    return tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "\n",
    "\n",
    "\n",
    "def solve_homography_forward_and_invert(src_pts, dst_pts):\n",
    "    #solve texture -> screen mapping, then get inverse\n",
    "\n",
    "    #normalize screen points to [-1, 1]\n",
    "\n",
    "    u_mean, v_mean = tf.reduce_mean(dst_pts[:, 0]), tf.reduce_mean(dst_pts[:, 1])\n",
    "    #shift\n",
    "    us = dst_pts[:, 0] - u_mean\n",
    "    vs = dst_pts[:, 1] - v_mean\n",
    "    \n",
    "    xs = src_pts[:, 0]\n",
    "    ys = src_pts[:, 1]\n",
    "    \n",
    "    #make forward matrix for x,y -> u,v\n",
    "    num_points = 4\n",
    "    A = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        x, y = xs[i], ys[i]\n",
    "        u, v = us[i], vs[i]\n",
    "        \n",
    "        A.append([x, y, 1.0, 0.0, 0.0, 0.0, -x*u, -y*u])\n",
    "        b.append(u)\n",
    "        A.append([0.0, 0.0, 0.0, x, y, 1.0, -x*v, -y*v])\n",
    "        b.append(v)\n",
    "        \n",
    "    A = tf.stack(A)\n",
    "    b = tf.stack(b)\n",
    "    b = tf.expand_dims(b, -1)\n",
    "    \n",
    "    #solve forward transform\n",
    "    h = tf.linalg.lstsq(A, b, l2_regularizer=1e-5, fast=True)\n",
    "    h = tf.reshape(h, [8])\n",
    "    \n",
    "    #make forward matrix\n",
    "    H_fwd = tf.stack([\n",
    "        [h[0], h[1], h[2]],\n",
    "        [h[3], h[4], h[5]],\n",
    "        [h[6], h[7], 1.0 ]\n",
    "    ])\n",
    "    \n",
    "    #invert forward matrix to get screen -> texture mat\n",
    "    H_inv = tf.linalg.inv(H_fwd)\n",
    "    \n",
    "    #undo earlier shift\n",
    "    T_shift = tf.stack([\n",
    "        [1.0, 0.0, -u_mean],\n",
    "        [0.0, 1.0, -v_mean],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    \n",
    "    H_final = tf.matmul(H_inv, T_shift)\n",
    "    \n",
    "    return H_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ba8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def render_texture_tf(texture, pitch, yaw, roll, distance, uv_scale=50.0, shift_u=0.0, shift_v=0.0, image_size=(500, 500)):\n",
    "    out_h, out_w = image_size\n",
    "    f = 500.0\n",
    "    cx, cy = out_w / 2.0, out_h / 2.0\n",
    "    \n",
    "    #upscale initial texture so it comes out crisp\n",
    "    high_res_tex = tf.image.resize(texture, [256, 256], method='nearest')\n",
    "    \n",
    "    #camera geometry\n",
    "    R = get_rotation_matrix_tf(pitch, yaw, roll)\n",
    "    plane_normal = R[:, 2] \n",
    "\n",
    "    #perspective\n",
    "    pixels_per_meter = 100.0 \n",
    "    center_dist_units = distance * pixels_per_meter\n",
    "    plane_point = tf.constant([0.0, 0.0, 0.0]) + (plane_normal * center_dist_units)\n",
    "\n",
    "    #ray casting\n",
    "    grid_x, grid_y = tf.meshgrid(tf.range(out_w), tf.range(out_h))\n",
    "    rx = tf.cast(grid_x, tf.float32) - cx\n",
    "    ry = tf.cast(grid_y, tf.float32) - cy\n",
    "    rz = tf.ones_like(rx) * f\n",
    "    ray_dir = tf.stack([rx, ry, rz], axis=-1)\n",
    "\n",
    "    #intersection\n",
    "    camera_pos = tf.constant([0.0, 0.0, -f])\n",
    "    numerator = tf.tensordot(plane_point - camera_pos, plane_normal, axes=1)\n",
    "    denominator = tf.tensordot(ray_dir, plane_normal, axes=1)\n",
    "    denominator = tf.where(tf.abs(denominator) < 1e-5, 1e-5, denominator)\n",
    "    t = numerator / denominator\n",
    "    hit_point = camera_pos + (ray_dir * tf.expand_dims(t, -1))\n",
    "\n",
    "    #uv mapping\n",
    "    hit_point_flat = tf.reshape(hit_point, [-1, 3])\n",
    "    relative_hit = hit_point_flat - plane_point\n",
    "    p_local_flat = tf.matmul(relative_hit, R) \n",
    "    p_local = tf.reshape(p_local_flat, [out_h, out_w, 3])\n",
    "    \n",
    "    raw_u = p_local[:, :, 0]\n",
    "    raw_v = p_local[:, :, 1]\n",
    "    \n",
    "    #scale\n",
    "    u = raw_u / uv_scale\n",
    "    v = raw_v / uv_scale\n",
    "    \n",
    "    #shifting the pattern (between 0, 1)\n",
    "    u = u + shift_u\n",
    "    v = v + shift_v\n",
    "    \n",
    "    #tile pattern\n",
    "    u = tf.math.floormod(u, 1.0)\n",
    "    v = tf.math.floormod(v, 1.0)\n",
    "    \n",
    "    #sample texture bilinearly\n",
    "    tex_h = tf.cast(tf.shape(high_res_tex)[0], tf.float32)\n",
    "    tex_w = tf.cast(tf.shape(high_res_tex)[1], tf.float32)\n",
    "    sample_x = u * (tex_w - 1.0)\n",
    "    sample_y = v * (tex_h - 1.0)\n",
    "    output = bilinear_sampler_tf(high_res_tex, sample_x, sample_y)\n",
    "    \n",
    "    #mask\n",
    "    valid_mask = t > 0.0\n",
    "    output = tf.where(tf.expand_dims(valid_mask, -1), output, tf.zeros_like(output))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelChoice = 'k3_100epch_wo_custom_loss_model.h5'\n",
    "model = keras.models.load_model(f'models/{modelChoice}', compile=False)\n",
    "\n",
    "\n",
    "textureResolution = 16\n",
    "initial_tex = np.random.randint(0, 256, (textureResolution, textureResolution, 3), dtype=np.uint8)\n",
    "tf_texture = tf.Variable(initial_tex.astype(np.float32) / 255.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "#ui setup\n",
    "display_widget = widgets.Image(format='jpeg', width=1000)\n",
    "sample_slider = widgets.IntSlider(value=0, min=0, max=max(0, len(sample_references)-1), description='Sample:', continuous_update=False)\n",
    "tex_scale_slider = widgets.FloatSlider(value=330.0, min=150.0, max=1000.0, step=1.0, description='Tex Scale:', continuous_update=False)\n",
    "shift_u_slider = widgets.FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Shift X:', continuous_update=True)\n",
    "shift_v_slider = widgets.FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Shift Y:', continuous_update=True)\n",
    "\n",
    "\n",
    "def to_uint8(img):\n",
    "    return (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def fast_render(sampleNo, texScale, shiftU, shiftV):\n",
    "    ref_img   = sample_references[sampleNo]\n",
    "    mask_img  = sample_masks[sampleNo]\n",
    "    overlay_mask   = sample_overlays[sampleNo]\n",
    "    transforms = sample_transforms[sampleNo] # [distance, pitch, yaw, vehicle_id]\n",
    "\n",
    "\n",
    "    raw_dist, raw_pitch, raw_yaw = int(transforms[0]), int(transforms[1]), int(transforms[2])\n",
    "    pitch, yaw, roll = calcTransforms(raw_pitch, raw_yaw)\n",
    "    \n",
    "    #convert scalar inputs to tensors\n",
    "    t_pitch = tf.convert_to_tensor(pitch, dtype=tf.float32)\n",
    "    t_yaw   = tf.convert_to_tensor(yaw, dtype=tf.float32)\n",
    "    t_roll  = tf.convert_to_tensor(roll, dtype=tf.float32)\n",
    "    t_dist  = tf.convert_to_tensor(raw_dist, dtype=tf.float32)\n",
    "    t_scale = tf.convert_to_tensor(texScale, dtype=tf.float32)\n",
    "    t_shift_u = tf.convert_to_tensor(shiftU, dtype=tf.float32)\n",
    "    t_shift_v = tf.convert_to_tensor(shiftV, dtype=tf.float32)\n",
    "    \n",
    "    #generate the texture & convert to numpy\n",
    "    tf_output = render_texture_tf(\n",
    "        tf_texture, t_pitch, t_yaw, t_roll, t_dist, \n",
    "        uv_scale=t_scale, \n",
    "        shift_u=t_shift_u, \n",
    "        shift_v=t_shift_v\n",
    "    )\n",
    "    transformed_tex = tf_output.numpy()\n",
    "\n",
    "    tex_mask = np.where(mask_img, transformed_tex, np.zeros_like(transformed_tex))\n",
    "\n",
    "\n",
    "    #generate dtn img\n",
    "    ref_img_input = np.expand_dims(ref_img, axis=0)\n",
    "    tex_mask_input = np.expand_dims(tex_mask, axis=0)\n",
    "    \n",
    "    outputs = model.predict([ref_img_input, tex_mask_input])\n",
    "    pred = outputs[0].astype(np.float32)\n",
    "    dtn_pred = np.where(overlay_mask, ref_img, pred)\n",
    "\n",
    "\n",
    "\n",
    "    #display results\n",
    "    combined = np.hstack((\n",
    "        to_uint8(ref_img),\n",
    "        to_uint8(transformed_tex),\n",
    "        to_uint8(dtn_pred)\n",
    "    ))\n",
    "\n",
    "    _, encoded = cv2.imencode(\n",
    "        '.jpg',\n",
    "        cv2.cvtColor(combined, cv2.COLOR_RGB2BGR),\n",
    "        [int(cv2.IMWRITE_JPEG_QUALITY), 80]\n",
    "    )\n",
    "    display_widget.value = encoded.tobytes()\n",
    "\n",
    "\n",
    "\n",
    "out = widgets.interactive_output(fast_render, {'sampleNo': sample_slider, 'texScale': tex_scale_slider, 'shiftU': shift_u_slider, 'shiftV': shift_v_slider})\n",
    "ui_controls = widgets.VBox([sample_slider, tex_scale_slider, shift_u_slider, shift_v_slider])\n",
    "display(ui_controls, display_widget, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
