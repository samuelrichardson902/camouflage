{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a37d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (1.21.6)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (8.1.8)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (1.62.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (7.31.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: backcall in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.43.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (6.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\samue\\miniconda3\\envs\\diss-carla\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow numpy matplotlib pandas scikit-learn opencv-python ipywidgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, Concatenate, Flatten, Dense, MaxPooling2D\n",
    "import keras.optimizers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "import time\n",
    "from IPython.display import clear_output, display\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6049976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, image_size=(500, 500), numImgs = (0, 100)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.png')) + glob(os.path.join(folder, '*.jpg')))\n",
    "    paths = sorted(paths, key=lambda x:int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    paths = paths[numImgs[0]:numImgs[1]]\n",
    "\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = keras.preprocessing.image.load_img(path, target_size=image_size)\n",
    "        img = keras.preprocessing.image.img_to_array(img).astype(np.float32)\n",
    "        img = img / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "\n",
    "# [[distance, pitch, yaw, vehicle_id_string],...]\n",
    "def load_transforms(folder, numImgs = (0, 100)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.npy')))\n",
    "    paths = sorted(paths, key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
    "\n",
    "    paths = paths[numImgs[0]:numImgs[1]]\n",
    "\n",
    "    transforms = []\n",
    "    for path in paths:\n",
    "        data = np.load(path) \n",
    "        transforms.append(data)\n",
    "    \n",
    "    return np.array(transforms)\n",
    "\n",
    "\n",
    "dataset_folder = 'sample_dataset'\n",
    "imgsToLoad = (101, 209)\n",
    "sample_references = load_images_from_folder(f\"{dataset_folder}/reference\", numImgs = imgsToLoad)\n",
    "sample_masks = load_images_from_folder(f\"{dataset_folder}/masks\", numImgs = imgsToLoad)\n",
    "sample_overlays = load_images_from_folder(f\"{dataset_folder}/overlays\", numImgs = imgsToLoad)\n",
    "sample_transforms = load_transforms(f\"{dataset_folder}/transforms\", numImgs = imgsToLoad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a1d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcTransforms(pitch, yaw):\n",
    "    yawdiff = ((yaw + 45) % 90) - 45 #the difference of yaw from the nearest 90 degree multiple\n",
    "    if pitch > 35: # top face is predominant\n",
    "        pitch = -pitch\n",
    "        yaw = -yawdiff\n",
    "        roll = 0\n",
    "\n",
    "    elif pitch < 15: # lowest orbit angle\n",
    "        pitch = pitch\n",
    "        roll = -yawdiff\n",
    "        yaw = 0\n",
    "    \n",
    "    else: # mid orbit angle\n",
    "        #if on front face\n",
    "        if 145 < yaw < 215:\n",
    "            yaw = -yawdiff\n",
    "            pitch = -pitch\n",
    "            roll = 0\n",
    "\n",
    "        else:\n",
    "            roll = -yawdiff\n",
    "            yaw = 0\n",
    "\n",
    "    return pitch, yaw, roll\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c8d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_matrix_tf(pitch, yaw, roll):\n",
    "    \"\"\"\n",
    "    Constructs a rotation matrix in TensorFlow matching YOUR original definitions.\n",
    "    \"\"\"\n",
    "    # Convert to radians\n",
    "    deg2rad = np.pi / 180.0\n",
    "    p = pitch * deg2rad\n",
    "    y = yaw * deg2rad\n",
    "    r = roll * deg2rad\n",
    "\n",
    "    # --- MATCHING YOUR ORIGINAL \"rotation_y\" (Pitch) ---\n",
    "    # Your code: pitch_mat = rotation_y(pitch_rad)\n",
    "    # Your rotation_y had 1 in the top-left (Standard X-Rotation)\n",
    "    rot_pitch = tf.stack([\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, tf.cos(p), -tf.sin(p)],\n",
    "        [0.0, tf.sin(p),  tf.cos(p)]\n",
    "    ])\n",
    "    \n",
    "    # --- MATCHING YOUR ORIGINAL \"rotation_x\" (Roll) ---\n",
    "    # Your code: roll_mat = rotation_x(roll_rad)\n",
    "    # Your rotation_x had 1 in the middle (Standard Y-Rotation)\n",
    "    rot_roll = tf.stack([\n",
    "        [ tf.cos(r), 0.0, tf.sin(r)],\n",
    "        [ 0.0,       1.0, 0.0],\n",
    "        [-tf.sin(r), 0.0, tf.cos(r)]\n",
    "    ])\n",
    "    \n",
    "    # --- MATCHING YOUR ORIGINAL \"rotation_z\" (Yaw) ---\n",
    "    # Your code: yaw_mat = rotation_z(yaw_rad)\n",
    "    rot_yaw = tf.stack([\n",
    "        [tf.cos(y), -tf.sin(y), 0.0],\n",
    "        [tf.sin(y),  tf.cos(y), 0.0],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    \n",
    "    # Combined: pitch_mat @ roll_mat @ yaw_mat\n",
    "    # We use vector-matrix multiplication order matching your original:\n",
    "    # res_mat = pitch_mat @ roll_mat @ yaw_mat\n",
    "    rot = tf.matmul(rot_pitch, tf.matmul(rot_roll, rot_yaw))\n",
    "    \n",
    "    return rot\n",
    "\n",
    "\n",
    "def bilinear_sampler_tf(img, x, y):\n",
    "    \"\"\"\n",
    "    Differentiable bilinear sampling.\n",
    "    img: (H, W, C)\n",
    "    x, y: (OutputH, OutputW) floats\n",
    "    \"\"\"\n",
    "    H = tf.shape(img)[0]\n",
    "    W = tf.shape(img)[1]\n",
    "    H_f = tf.cast(H, tf.float32)\n",
    "    W_f = tf.cast(W, tf.float32)\n",
    "    \n",
    "    x = tf.clip_by_value(x, 0.0, W_f - 1.001)\n",
    "    y = tf.clip_by_value(y, 0.0, H_f - 1.001)\n",
    "    \n",
    "    x0 = tf.cast(tf.floor(x), tf.int32)\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.cast(tf.floor(y), tf.int32)\n",
    "    y1 = y0 + 1\n",
    "    \n",
    "    # Get values\n",
    "    Ia = tf.gather_nd(img, tf.stack([y0, x0], axis=-1))\n",
    "    Ib = tf.gather_nd(img, tf.stack([y1, x0], axis=-1))\n",
    "    Ic = tf.gather_nd(img, tf.stack([y0, x1], axis=-1))\n",
    "    Id = tf.gather_nd(img, tf.stack([y1, x1], axis=-1))\n",
    "    \n",
    "    wa = (tf.cast(x1, tf.float32) - x) * (tf.cast(y1, tf.float32) - y)\n",
    "    wb = (tf.cast(x1, tf.float32) - x) * (y - tf.cast(y0, tf.float32))\n",
    "    wc = (x - tf.cast(x0, tf.float32)) * (tf.cast(y1, tf.float32) - y)\n",
    "    wd = (x - tf.cast(x0, tf.float32)) * (y - tf.cast(y0, tf.float32))\n",
    "    \n",
    "    wa = tf.expand_dims(wa, -1)\n",
    "    wb = tf.expand_dims(wb, -1)\n",
    "    wc = tf.expand_dims(wc, -1)\n",
    "    wd = tf.expand_dims(wd, -1)\n",
    "    \n",
    "    return tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "\n",
    "\n",
    "\n",
    "def solve_homography_forward_and_invert(src_pts, dst_pts):\n",
    "    \"\"\"\n",
    "    1. Solves H_forward mapping src (Texture) -> dst (Screen).\n",
    "       This is numerically STABLE because src is always a perfect square.\n",
    "    2. Returns H_inv = inv(H_forward).\n",
    "    \"\"\"\n",
    "    # 1. Normalize the destination points (Screen) to [-1, 1] range \n",
    "    #    to improve numerical stability (Hartley normalization).\n",
    "    #    Screen is approx 0..500. Centering it helps the solver.\n",
    "    u_mean, v_mean = tf.reduce_mean(dst_pts[:, 0]), tf.reduce_mean(dst_pts[:, 1])\n",
    "    # Simple shift, scale is less critical here but shift is vital\n",
    "    us = dst_pts[:, 0] - u_mean\n",
    "    vs = dst_pts[:, 1] - v_mean\n",
    "    \n",
    "    xs = src_pts[:, 0]\n",
    "    ys = src_pts[:, 1]\n",
    "    \n",
    "    # Build Matrix for H_forward\n",
    "    # Maps (x,y) -> (u,v) (Texture -> Screen)\n",
    "    num_points = 4\n",
    "    A = []\n",
    "    b = []\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        x, y = xs[i], ys[i]\n",
    "        u, v = us[i], vs[i]\n",
    "        \n",
    "        # Standard DLT for Forward mapping\n",
    "        A.append([x, y, 1.0, 0.0, 0.0, 0.0, -x*u, -y*u])\n",
    "        b.append(u)\n",
    "        A.append([0.0, 0.0, 0.0, x, y, 1.0, -x*v, -y*v])\n",
    "        b.append(v)\n",
    "        \n",
    "    A = tf.stack(A)\n",
    "    b = tf.stack(b)\n",
    "    b = tf.expand_dims(b, -1)\n",
    "    \n",
    "    # Solve stable forward transform\n",
    "    h = tf.linalg.lstsq(A, b, l2_regularizer=1e-5, fast=True)\n",
    "    h = tf.reshape(h, [8])\n",
    "    \n",
    "    # Construct Forward Matrix\n",
    "    H_fwd = tf.stack([\n",
    "        [h[0], h[1], h[2]],\n",
    "        [h[3], h[4], h[5]],\n",
    "        [h[6], h[7], 1.0 ]\n",
    "    ])\n",
    "    \n",
    "    # 2. Invert to get the mapping we actually need (Screen -> Texture)\n",
    "    H_inv = tf.linalg.inv(H_fwd)\n",
    "    \n",
    "    # 3. Account for the shift we applied earlier\n",
    "    # To undo the shift: H_final = H_inv * T_shift\n",
    "    T_shift = tf.stack([\n",
    "        [1.0, 0.0, -u_mean],\n",
    "        [0.0, 1.0, -v_mean],\n",
    "        [0.0, 0.0, 1.0]\n",
    "    ])\n",
    "    \n",
    "    H_final = tf.matmul(H_inv, T_shift)\n",
    "    \n",
    "    return H_final\n",
    "\n",
    "@tf.function\n",
    "def render_texture_tf(texture, pitch, yaw, roll, distance, uv_scale=50.0, shift_u=0.0, shift_v=0.0, image_size=(500, 500)):\n",
    "    out_h, out_w = image_size\n",
    "    f = 500.0\n",
    "    cx, cy = out_w / 2.0, out_h / 2.0\n",
    "    \n",
    "    # --- 1. SHARPNESS TRICK ---\n",
    "    high_res_tex = tf.image.resize(texture, [256, 256], method='nearest')\n",
    "    \n",
    "    # --- 2. CAMERA GEOMETRY ---\n",
    "    R = get_rotation_matrix_tf(pitch, yaw, roll)\n",
    "    plane_normal = R[:, 2] \n",
    "\n",
    "    # --- 3. PERSPECTIVE LOGIC ---\n",
    "    pixels_per_meter = 100.0 \n",
    "    center_dist_units = distance * pixels_per_meter\n",
    "    plane_point = tf.constant([0.0, 0.0, 0.0]) + (plane_normal * center_dist_units)\n",
    "\n",
    "    # --- 4. RAY CASTING ---\n",
    "    grid_x, grid_y = tf.meshgrid(tf.range(out_w), tf.range(out_h))\n",
    "    rx = tf.cast(grid_x, tf.float32) - cx\n",
    "    ry = tf.cast(grid_y, tf.float32) - cy\n",
    "    rz = tf.ones_like(rx) * f\n",
    "    ray_dir = tf.stack([rx, ry, rz], axis=-1)\n",
    "\n",
    "    # --- 5. INTERSECTION ---\n",
    "    camera_pos = tf.constant([0.0, 0.0, -f])\n",
    "    numerator = tf.tensordot(plane_point - camera_pos, plane_normal, axes=1)\n",
    "    denominator = tf.tensordot(ray_dir, plane_normal, axes=1)\n",
    "    denominator = tf.where(tf.abs(denominator) < 1e-5, 1e-5, denominator)\n",
    "    t = numerator / denominator\n",
    "    hit_point = camera_pos + (ray_dir * tf.expand_dims(t, -1))\n",
    "\n",
    "    # --- 6. UV MAPPING ---\n",
    "    hit_point_flat = tf.reshape(hit_point, [-1, 3])\n",
    "    relative_hit = hit_point_flat - plane_point\n",
    "    p_local_flat = tf.matmul(relative_hit, R) \n",
    "    p_local = tf.reshape(p_local_flat, [out_h, out_w, 3])\n",
    "    \n",
    "    raw_u = p_local[:, :, 0]\n",
    "    raw_v = p_local[:, :, 1]\n",
    "    \n",
    "    # Scale\n",
    "    u = raw_u / uv_scale\n",
    "    v = raw_v / uv_scale\n",
    "    \n",
    "    # --- SHIFTING (Translation) ---\n",
    "    # Add the shift offset. \n",
    "    # 0.0 = No shift, 0.5 = Half tile shift, 1.0 = Full tile shift (Same as 0.0)\n",
    "    u = u + shift_u\n",
    "    v = v + shift_v\n",
    "    \n",
    "    # Tiling\n",
    "    u = tf.math.floormod(u, 1.0)\n",
    "    v = tf.math.floormod(v, 1.0)\n",
    "    \n",
    "    # --- 7. SAMPLING ---\n",
    "    tex_h = tf.cast(tf.shape(high_res_tex)[0], tf.float32)\n",
    "    tex_w = tf.cast(tf.shape(high_res_tex)[1], tf.float32)\n",
    "    \n",
    "    sample_x = u * (tex_w - 1.0)\n",
    "    sample_y = v * (tex_h - 1.0)\n",
    "    \n",
    "    output = bilinear_sampler_tf(high_res_tex, sample_x, sample_y)\n",
    "    \n",
    "    # --- 8. MASKING ---\n",
    "    valid_mask = t > 0.0\n",
    "    output = tf.where(tf.expand_dims(valid_mask, -1), output, tf.zeros_like(output))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2abc3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971848d0ad684490b0cf1bc8b16b7771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, description='Sample:', max=107), FloatSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2d402bc4d94913a477e2a06e23401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x06\\x04\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8047dcb7e4f74c128a09537fd4956bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "textureResolution = 16\n",
    "initial_tex = np.random.randint(0, 256, (textureResolution, textureResolution, 3), dtype=np.uint8)\n",
    "# Convert to Variable for TF optimization\n",
    "tf_texture = tf.Variable(initial_tex.astype(np.float32) / 255.0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# --- UI Setup ---\n",
    "display_widget = widgets.Image(format='jpeg', width=1000)\n",
    "info_label = widgets.HTML(value=\"<b>Initializing...</b>\")\n",
    "\n",
    "sample_slider = widgets.IntSlider(value=0, min=0, max=max(0, len(sample_references)-1), description='Sample:', continuous_update=False)\n",
    "tex_scale_slider = widgets.FloatSlider(value=330.0, min=150.0, max=1000.0, step=1.0, description='Tex Scale:', continuous_update=False)\n",
    "\n",
    "shift_u_slider = widgets.FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Shift X:', continuous_update=True)\n",
    "shift_v_slider = widgets.FloatSlider(value=0.0, min=0.0, max=1.0, step=0.05, description='Shift Y:', continuous_update=True)\n",
    "\n",
    "def to_uint8(img):\n",
    "    return (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "def fast_render(sampleNo, texScale, shiftU, shiftV):\n",
    "    if sampleNo >= len(sample_references):\n",
    "        return\n",
    "\n",
    "    # 1. Get Data\n",
    "    ref_img   = sample_references[sampleNo] # Already float 0-1\n",
    "    mask_img  = sample_masks[sampleNo]\n",
    "    overlay   = sample_overlays[sampleNo]\n",
    "    transforms = sample_transforms[sampleNo] \n",
    "    # [distance, pitch, yaw, vehicle_id]\n",
    "\n",
    "    # 2. Pre-process Angles (Numpy)\n",
    "    raw_dist, raw_pitch, raw_yaw = int(transforms[0]), int(transforms[1]), int(transforms[2])\n",
    "    pitch, yaw, roll = calcTransforms(raw_pitch, raw_yaw)\n",
    "    \n",
    "    # 3. Differentiable Render (TensorFlow)\n",
    "    # Convert scalar inputs to tensors\n",
    "    t_pitch = tf.convert_to_tensor(pitch, dtype=tf.float32)\n",
    "    t_yaw   = tf.convert_to_tensor(yaw, dtype=tf.float32)\n",
    "    t_roll  = tf.convert_to_tensor(roll, dtype=tf.float32)\n",
    "    t_dist  = tf.convert_to_tensor(raw_dist, dtype=tf.float32)\n",
    "\n",
    "    t_scale = tf.convert_to_tensor(texScale, dtype=tf.float32)\n",
    "\n",
    "    t_shift_u = tf.convert_to_tensor(shiftU, dtype=tf.float32)\n",
    "    t_shift_v = tf.convert_to_tensor(shiftV, dtype=tf.float32)\n",
    "    \n",
    "    # Run the graph function\n",
    "    # Returns (500, 500, 3) Tensor\n",
    "    tf_output = render_texture_tf(\n",
    "        tf_texture, t_pitch, t_yaw, t_roll, t_dist, \n",
    "        uv_scale=t_scale, \n",
    "        shift_u=t_shift_u, \n",
    "        shift_v=t_shift_v\n",
    "    )\n",
    "    \n",
    "    # Convert back to Numpy for display\n",
    "    transformed_tex = tf_output.numpy()\n",
    "\n",
    "    # 4. Composite (Numpy)\n",
    "    road_mask = np.any(mask_img > 0.01, axis=-1, keepdims=True)\n",
    "    car_mask  = np.any(overlay  > 0.01, axis=-1, keepdims=True)\n",
    "    apply_tex = road_mask & ~car_mask\n",
    "\n",
    "    final_comp = np.where(apply_tex, transformed_tex, ref_img)\n",
    "\n",
    "    # 5. Display\n",
    "    combined = np.hstack((\n",
    "        to_uint8(ref_img),\n",
    "        to_uint8(transformed_tex),\n",
    "        to_uint8(final_comp)\n",
    "    ))\n",
    "\n",
    "    _, encoded = cv2.imencode(\n",
    "        '.jpg',\n",
    "        cv2.cvtColor(combined, cv2.COLOR_RGB2BGR),\n",
    "        [int(cv2.IMWRITE_JPEG_QUALITY), 80]\n",
    "    )\n",
    "    display_widget.value = encoded.tobytes()\n",
    "\n",
    "    info_label.value = f\"\"\"\n",
    "    <div style=\"font-family: monospace; font-size: 14px;\">\n",
    "        <b>Original:</b> Dist:{raw_dist:.1f}, P:{raw_pitch:.1f}, Y:{raw_yaw:.1f} <br>\n",
    "        <b>Adjusted:</b> P:{pitch:.1f}, Y:{yaw:.1f}, R:{roll:.1f}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "out = widgets.interactive_output(fast_render, {'sampleNo': sample_slider, 'texScale': tex_scale_slider, 'shiftU': shift_u_slider, 'shiftV': shift_v_slider})\n",
    "ui_controls = widgets.VBox([sample_slider, tex_scale_slider, shift_u_slider, shift_v_slider, info_label])\n",
    "display(ui_controls, display_widget, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
