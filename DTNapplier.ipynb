{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0c9a89",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d66884",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow numpy matplotlib pandas scikit-learn opencv-python ipywidgets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import Conv2D, Concatenate, Flatten, Dense, MaxPooling2D\n",
    "import keras.optimizers\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation helper functions\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transform_projection(image, rotation, shift, scale):\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # ---- Parameters ----\n",
    "    shift_x, shift_y = shift     # pixels\n",
    "    rot_x, rot_y, rot_z = rotation   # degrees of 3D rotation\n",
    "\n",
    "    # ---- Build Projection Matrix ----\n",
    "    f = 500\n",
    "    cx, cy = w//2, h//2\n",
    "\n",
    "    \n",
    "\n",
    "    # Define corner points in 3D\n",
    "    corners_3d = np.array([\n",
    "        [-w/2, -h/2, 0],\n",
    "        [ w/2, -h/2, 0],\n",
    "        [ w/2,  h/2, 0],\n",
    "        [-w/2,  h/2, 0]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    # Apply rotation\n",
    "    R = rotation_matrix(rot_x, rot_y, rot_z)\n",
    "    rotated = corners_3d @ R.T\n",
    "\n",
    "    # Apply scaling\n",
    "    rotated *= scale\n",
    "\n",
    "    # Project back to 2D\n",
    "    projected = rotated.copy()\n",
    "    projected[:,0] = f * projected[:,0] / (f + projected[:,2]) + cx + shift_x\n",
    "    projected[:,1] = f * projected[:,1] / (f + projected[:,2]) + cy + shift_y\n",
    "\n",
    "    # Warp perspective\n",
    "    src_pts = np.array([[0,0],[w,0],[w,h],[0,h]], dtype=np.float32)\n",
    "    dst_pts = projected[:,:2].astype(np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "\n",
    "    output = cv2.warpPerspective(image, M, (w+200, h+200))\n",
    "    return np.clip(output, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "def rotation_matrix(rx, ry, rz):\n",
    "        rx, ry, rz = np.deg2rad([rx, ry, rz])\n",
    "        Rx = np.array([[1, 0, 0],\n",
    "                    [0, np.cos(rx), -np.sin(rx)],\n",
    "                    [0, np.sin(rx),  np.cos(rx)]])\n",
    "        Ry = np.array([[ np.cos(ry), 0, np.sin(ry)],\n",
    "                    [0, 1, 0],\n",
    "                    [-np.sin(ry), 0, np.cos(ry)]])\n",
    "        Rz = np.array([[np.cos(rz), -np.sin(rz), 0],\n",
    "                    [np.sin(rz),  np.cos(rz), 0],\n",
    "                    [0, 0, 1]])\n",
    "        return Rz @ Ry @ Rx \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc95ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, image_size=(500, 500)):\n",
    "    paths = sorted(glob(os.path.join(folder, '*.png')) + glob(os.path.join(folder, '*.jpg')))\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        img = keras.preprocessing.image.load_img(path, target_size=image_size)\n",
    "        img = keras.preprocessing.image.img_to_array(img).astype(np.float32)\n",
    "        img = img / 255.0  # Normalize to [0,1]\n",
    "        images.append(img)\n",
    "    return np.array(images, dtype=np.float32)\n",
    "\n",
    "print(\"Loading validation datasets...\")\n",
    "val_x_ref = load_images_from_folder('validation_dataset_clean/reference')\n",
    "val_eta_exp = load_images_from_folder('validation_dataset_clean/texture')\n",
    "val_x_ren = load_images_from_folder('validation_dataset_clean/rendered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bf2a2",
   "metadata": {},
   "source": [
    "# Create & Transform Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def to_float32_unit(image):\n",
    "    image = np.asarray(image, dtype=np.float32)\n",
    "    if image.max() > 1.0 or image.min() < 0.0:\n",
    "        image /= 255.0\n",
    "    return np.clip(image, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "def generateTransformedTex(\n",
    "    textureStyle = 'noise',\n",
    "    textureRepeated = False,\n",
    "    textureResolution = 32,\n",
    "    textureRandomSeed = 32,\n",
    "    rotation = (0, 20, 45),\n",
    "    shift = (40, 40),\n",
    "    scale = 2.2\n",
    "):\n",
    "    \n",
    "\n",
    "\n",
    "    if textureStyle == 'noise':\n",
    "        texture = np.random.rand(textureResolution, textureResolution, 3).astype(np.float32)\n",
    "    elif textureStyle == 'mud':\n",
    "        texture = to_float32_unit(\n",
    "            Image.open('textures/mud.png').convert('RGB').resize((100, 100), resample=Image.NEAREST)\n",
    "        )\n",
    "    elif textureStyle == 'snow':\n",
    "        texture = to_float32_unit(\n",
    "            Image.open('textures/snow.png').convert('RGB').resize((100, 100), resample=Image.NEAREST)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported texture style '{textureStyle}'\")\n",
    "\n",
    "\n",
    "    if textureRepeated and textureStyle == 'noise':\n",
    "        tile_rows = 500 // texture.shape[0] + 1\n",
    "        tile_cols = 500 // texture.shape[1] + 1\n",
    "        tiled_texture = np.tile(texture, (tile_rows, tile_cols, 1))[:500, :500, :]\n",
    "    elif textureRepeated and textureStyle != 'noise':\n",
    "        canvas = np.zeros((500, 500, 3), dtype=np.float32)\n",
    "        tex_h, tex_w = texture.shape[:2]\n",
    "\n",
    "        np.random.seed(textureRandomSeed)  # For reproducibility\n",
    "\n",
    "        for y in range(0, 500, tex_h):\n",
    "            for x in range(0, 500, tex_w):\n",
    "                y0 = np.clip(y + np.random.randint(-tex_h//4, tex_h//4), 0, 500 - tex_h)\n",
    "                x0 = np.clip(x + np.random.randint(-tex_w//4, tex_w//4), 0, 500 - tex_w)\n",
    "                y_end = y0 + tex_h\n",
    "                x_end = x0 + tex_w\n",
    "\n",
    "                patch = texture.copy()\n",
    "                if np.random.rand() < 0.5:\n",
    "                    patch = np.flipud(patch)\n",
    "                if np.random.rand() < 0.5:\n",
    "                    patch = np.fliplr(patch)\n",
    "\n",
    "                canvas[y0:y_end, x0:x_end] = patch\n",
    "\n",
    "        tiled_texture = canvas\n",
    "    else:  # if not repeated, resize it\n",
    "        tiled_texture = cv2.resize(texture, (500, 500), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "    tiled_texture = to_float32_unit(tiled_texture)\n",
    "\n",
    "\n",
    "\n",
    "    transformed_tex_unsized = transform_projection(tiled_texture, rotation, shift, scale = scale)\n",
    "    transformed_tex = cv2.resize(\n",
    "        transformed_tex_unsized, (500, 500), interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "    transformed_tex = np.clip(transformed_tex, 0.0, 1.0).astype(np.float32)\n",
    "\n",
    "\n",
    "    return transformed_tex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display(model, ref, tex, cross_ref, transformed_tex):\n",
    "    outputs = model.predict([ref, tex])\n",
    "    pred = outputs[0].astype(np.float32)\n",
    "\n",
    "    # Compute intersection (where rendered and reference are nearly equal)\n",
    "    intersection_mask = np.isclose(cross_ref, ref, atol=1e-2).all(axis=-1, keepdims=True)\n",
    "\n",
    "    # Overlay: only keep intersecting pixels in prediction\n",
    "    overlay_preds = np.where(intersection_mask, ref, pred)\n",
    "\n",
    "    def _imshow(ax, image, title, cmap=None):\n",
    "        ax.set_title(title)\n",
    "        if cmap:\n",
    "            ax.imshow(image, cmap=cmap)\n",
    "        else:\n",
    "            ax.imshow(np.clip(image, 0.0, 1.0))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    _imshow(fig.add_subplot(2, 3, 1), ref[0], \"Reference\")\n",
    "\n",
    "    _imshow(fig.add_subplot(2, 3, 2), transformed_tex, \"Texture\")\n",
    "\n",
    "    _imshow(fig.add_subplot(2, 3, 3), tex[0], \"Texture Mask\")\n",
    "\n",
    "\n",
    "    tex_overlay = np.where(intersection_mask, ref, tex)\n",
    "    _imshow(fig.add_subplot(2, 3, 4), tex_overlay[0], \"Texture + mask overlay\")\n",
    "\n",
    "    _imshow(fig.add_subplot(2, 3, 5), pred, \"Prediction no overlay\")\n",
    "\n",
    "    _imshow(fig.add_subplot(2, 3, 6), overlay_preds[0], \"Prediction + mask overlay\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede39750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAYBE RE-TRAIN MODELS WITH LESS NODES? COLOURISARION ISSUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729f249",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ea33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imageNo = 63\n",
    "modelChoice = 'k3_100epch_wo_custom_loss_model.h5'\n",
    "textureStyle = 'noise'\n",
    "textureRepeated = False\n",
    "textureResolution = 32\n",
    "textureRandomSeed = 32\n",
    "rotation = (0, 20, 45)\n",
    "shift = (40, 40)\n",
    "scale = 2.2 # scale = 1.0 --> no scaling\n",
    "\n",
    "\n",
    "\n",
    "transformed_tex = generateTransformedTex(\n",
    "    textureStyle,\n",
    "    textureRepeated,\n",
    "    textureResolution,\n",
    "    textureRandomSeed,\n",
    "    rotation,\n",
    "    shift,\n",
    "    scale\n",
    ")\n",
    "\n",
    "\n",
    "# Apply texture to masked regions\n",
    "mask = np.any(val_eta_exp[imageNo] > 0.01, axis=-1, keepdims=True)  # Shape: (500, 500, 1)\n",
    "texture_mask = np.where(mask, transformed_tex, np.zeros_like(transformed_tex))\n",
    "\n",
    "model = keras.models.load_model(f'models/{modelChoice}', compile=False)\n",
    "\n",
    "refInput = np.expand_dims(val_x_ref[imageNo], axis=0).astype(np.float32)  # shape: (1, 500, 500, 3)\n",
    "texInput = np.expand_dims(texture_mask, axis=0).astype(np.float32)  # shape: (1, 500, 500, 3)\n",
    "cross_ref = np.expand_dims(val_x_ren[imageNo], axis=0).astype(np.float32)  # shape: (1, 500, 500, 3)\n",
    "\n",
    "predict_and_display(model, refInput, texInput, cross_ref, transformed_tex)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-carla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
